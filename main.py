import speech_recognition as sr
from gtts import gTTS
# import playsound # Replacing with pydub
import os
import time
# import config # No longer needed, config is inline
from fuzzywuzzy import process
from collections import deque
import random
import re # Import regex for name extraction
from langdetect import detect, LangDetectException # Import langdetect
import google.generativeai as genai # Gemini API
from pydub import AudioSegment # For audio playback
from pydub.playback import play # For audio playback
import tempfile # For temporary audio files

# --- Configuration Settings (formerly config.py) ---

# Supported Languages
# Define the languages the bot can understand and speak
# Format: { "short_code": {"tts": "google_tts_code", "stt": "google_stt_code"} }
# Note: SpeechRecognition uses BCP-47 codes (e.g., "bn-BD"), gTTS uses simpler codes (e.g., "bn")
SUPPORTED_LANGUAGES = {
    "en": {"tts": "en", "stt": "en-US"},  # English
    "bn": {"tts": "bn", "stt": "bn-BD"}   # Bengali (Bangladesh)
}
DEFAULT_LANGUAGE = "en" # Default language if detection fails or for initial messages

# Temporary file path for TTS audio output
AUDIO_FILE = "response.mp3"

# Wake word settings (Keep wake words primarily in one language for simplicity, e.g., English)
WAKE_WORD_ENABLED = True
WAKE_WORDS = ["hey shadow bot", "shadow bot", "hey shadow", "shadow"] # English wake words
WAKE_WORD_LANG_STT = "en-US" # STT Language for wake word recognition
WAKE_WORD_TIMEOUT = 10  # Seconds to listen for a command after wake word

# Command parsing settings
COMMAND_SIMILARITY_THRESHOLD = 0.7  # Threshold for fuzzy matching commands (0.0 to 1.0)

# Contextual conversation settings
CONTEXT_MEMORY_SIZE = 5  # Number of previous interactions to remember

# Error handling settings
MAX_RETRY_ATTEMPTS = 3  # Maximum number of retries for failed operations
RETRY_DELAY = 2  # Seconds to wait between retries

# --- Microphone Listening Settings ---
# Adjust based on microphone sensitivity and environment noise
# Higher values require louder speech to be detected
DYNAMIC_ENERGY_THRESHOLD = True # Let the library adjust energy threshold automatically
# If DYNAMIC_ENERGY_THRESHOLD is False, uncomment and set manually:
# ENERGY_THRESHOLD = 3000 
PAUSE_THRESHOLD = 0.8  # Seconds of non-speaking audio before phrase is considered complete
PHRASE_TIME_LIMIT = 10 # Max seconds for a single phrase/command
ADJUST_NOISE_DURATION = 1 # Seconds to adjust for ambient noise on startup/wake

# --- Gemini API Configuration ---
# WARNING: Storing API keys directly in code is insecure. Consider environment variables.
GEMINI_API_KEY = "AIzaSyBY88kNHfPUqauW2z5wu5-qnBv1Kr4d86s" # Replace with your actual key if different
try:
    genai.configure(api_key=GEMINI_API_KEY)
    # Using gemini-1.5-flash as gemini-2.0-flash might not be a valid model name yet
    gemini_model = genai.GenerativeModel('gemini-1.5-flash') 
    print("Gemini model initialized successfully.")
except Exception as e:
    print(f"Error initializing Gemini API: {e}")
    gemini_model = None # Set model to None if initialization fails

# --- Chat Context Memory ---
chat_history = []
MAX_CHAT_HISTORY = 10  # Maximum number of interactions to remember

def add_to_chat_history(role, content):
    """Add a message to chat history and maintain the size limit."""
    chat_history.append({"role": role, "content": content})
    if len(chat_history) > MAX_CHAT_HISTORY:
        chat_history.pop(0)  # Remove oldest message

def get_gemini_response(prompt):
    """Sends a prompt to the Gemini API and returns the response text."""
    if gemini_model is None:
        print("Gemini model not initialized. Cannot get response.")
        return get_response_string("gemini_error")

    print(f"Sending prompt to Gemini: {prompt}")
    try:
        # Add user's message to chat history
        add_to_chat_history("user", prompt)
        
        # Create context-aware prompt with instructions for concise response
        context_prompt = "You are a voice assistant. Keep responses brief and conversational (1-2 sentences). Previous conversation:\n"
        for msg in chat_history[:-1]:  # Exclude the current message
            context_prompt += f"{msg['role']}: {msg['content']}\n"
        context_prompt += f"\nCurrent message:\n{prompt}\n\nRemember: Keep your response brief and conversational."
        
        response = gemini_model.generate_content(context_prompt)
        cleaned_text = re.sub(r'[*#]', '', response.text).strip()
        
        # Further clean up response to ensure it's concise
        # Split into sentences and take first 2 if there are more
        sentences = cleaned_text.split('.')
        sentences = [s.strip() for s in sentences if s.strip()]
        if len(sentences) > 2:
            cleaned_text = '. '.join(sentences[:2]) + '.'
        
        print(f"Gemini Response: {cleaned_text}")
        
        # Add Gemini's response to chat history
        add_to_chat_history("assistant", cleaned_text)
        
        return cleaned_text
    except Exception as e:
        print(f"Gemini API error: {e}")
        return get_response_string("gemini_error")

# Modify the wake word logic
wake_word_activated = False

def listen_for_wake_word():
    """
    Listen for wake word only once at startup.
    """
    global wake_word_activated
    
    if not WAKE_WORD_ENABLED or wake_word_activated:
        return True

    print("Listening for wake word...")

    r_wake = sr.Recognizer()
    for attempt in range(MAX_RETRY_ATTEMPTS):
        audio = listen_for_audio(timeout=None, phrase_time_limit=3, adjust_noise=(attempt == 0))
        if audio is None:
            continue

        try:
            text = r_wake.recognize_google(audio, language="en-US")
            print(f"Wake word attempt recognized: {text}")
            text_lower = text.lower()
            if any(wake_word in text_lower for wake_word in WAKE_WORDS):
                print(f"Wake word detected: {text}")
                wake_word_activated = True
                return True
        except sr.UnknownValueError:
            pass
        except sr.RequestError as e:
            print(f"Wake word recognition request failed; {e}")
            continue
        except Exception as e:
            print(f"Error during wake word recognition: {e}")
            continue

    print("Wake word not detected.")
    return False

# --- Bot Logic (formerly bot_brain.py) ---

# --- Context Memory ---
context_memory = deque(maxlen=CONTEXT_MEMORY_SIZE) # Use variable directly

# --- Bilingual Data Structures ---

# Command Templates (Nested by language)
command_templates = {
    "en": {
        "greeting": ["hello", "hi", "hey", "greetings", "good morning", "good afternoon", "good evening"],
        "time": ["what time is it", "tell me the time", "current time", "time now", "what's the time"],
        "name": ["what's your name", "who are you", "your name", "tell me your name", "introduce yourself"],
        "joke": ["tell me a joke", "say something funny", "make me laugh", "joke", "know any jokes"],
        "exit": ["stop", "exit", "quit", "goodbye", "bye", "shut down", "turn off"],
        "how_are_you": ["how are you", "how are you doing", "how's it going", "how do you feel", "are you okay"],
        "thanks": ["thank you", "thanks", "appreciate it", "that's helpful", "great job"],
        "weather": ["what's the weather", "how's the weather", "is it raining", "temperature today", "forecast"],
        "capabilities": ["what can you do", "help", "list commands", "your abilities", "what are you capable of", "features"],
        "about_you": ["tell me about yourself", "what are you", "are you a robot", "are you human", "are you ai"],
        "user_name": ["my name is", "call me", "i am", "i'm called"],
        "how_made": ["how were you made", "who made you", "who created you", "your creator", "how were you created"],
        "yes": ["yes", "yeah", "sure", "absolutely", "correct", "that's right", "yep", "ok", "okay"],
        "no": ["no", "nope", "not really", "i don't think so", "negative", "not at all"],
        "why": ["why", "why is that", "how come", "for what reason", "explain why"],
        "what_else": ["what else", "tell me more", "continue", "go on", "anything else", "more information"]
    },
    "bn": {
        "greeting": ["??????", "???", "?????", "????????", "??? ????", "??? ?????", "??? ???????"],
        "time": ["????? ????", "???? ??", "??? ????? ????", "???? ????", "??????? ????"],
        "name": ["????? ??? ??", "???? ??", "????? ???", "????? ??? ???", "?????? ???"],
        "joke": ["???? ???? ???", "???? ???? ???", "?????", "????", "????? ???"],
        "exit": ["???? ???", "????", "??????", "???", "???? ??", "??? ??"],
        "how_are_you": ["???? ???", "???? ????", "?? ???", "???? ????", "???? ??? ????"],
        "thanks": ["???????", "??????? ??", "???? ???????", "????????? ???? ???????", "??? ????"],
        "weather": ["???????? ????", "????? ????????", "?????? ?????", "????? ?????????", "????????? ?????????"],
        "capabilities": ["???? ?? ???? ????", "???????", "?????? ?????", "????? ??????", "?? ?? ????", "?????"],
        "about_you": ["????? ???????? ???", "???? ??", "???? ?? ????", "???? ?? ?????", "???? ?? ???"],
        "user_name": ["???? ???", "????? ?????", "??? ????", "???? ??? ???"],
        "how_made": ["?????? ?????? ?????? ??????", "?? ?????????", "????? ??????? ??", "?????? ???? ??????"],
        "yes": ["?????", "??", "??????", "???", "?????", "???"],
        "no": ["??", "?? ??", "???? ??", "??? ??? ??", "???????"],
        "why": ["???", "?? ????", "?? ?????", "???? ??", "???????? ???"],
        "what_else": ["?? ??", "??? ???", "??????? ???", "?? ????", "??? ????"]
    }
}

# Responses (Nested by language)
responses = {
    "en": {
        "greeting": [
            "Hello there! How can I help?", "Hi! What can I do for you?",
            "Hey! Nice to hear from you.", "Greetings! I'm at your service."
        ],
        "greeting_repeat": "Hello again! You seem friendly today. How can I help?",
        "greeting_followup": " How are you doing today?",
        "how_are_you": [
            "I'm doing well, thank you for asking! How about you?", "I'm functioning perfectly! How are you?",
            "All systems operational! How's your day going?", "I'm great! Thanks for asking. How are you doing?"
        ],
        "how_are_you_resp_glad": "I'm glad to hear that! What can I help you with today?",
        "how_are_you_resp_sorry": "I'm sorry to hear that. Is there anything I can do to help?",
        "time": "The current time is {current_time}.",
        "time_repeat": "It's still {current_time}. Time flies when you're having fun!",
        "name": "My name is Shadow Bot. I'm your voice assistant.",
        "name_repeat": "As I mentioned, I'm Shadow Bot. I won't forget my name, I promise!",
        "name_ask": "My name is Shadow Bot. I'm your voice assistant. What's your name?",
        "user_name_confirm": "Nice to meet you, {name}! How can I help you today?",
        "user_name_fail": "I didn't quite catch your name. Could you tell me again?",
        "joke": [
            "Why don't scientists trust atoms? Because they make up everything!", "What do you call a fake noodle? An impasta!",
            "Why did the scarecrow win an award? Because he was outstanding in his field!", "How does a penguin build its house? Igloos it together!",
            "Why don't eggs tell jokes? They'd crack each other up!", "What did the ocean say to the beach? Nothing, it just waved!",
            "Why did the bicycle fall over? Because it was two-tired!", "What's orange and sounds like a parrot? A carrot!",
            "Why can't you give Elsa a balloon? Because she will let it go!", "I told my wife she was drawing her eyebrows too high. She looked surprised!"
        ],
        "joke_ask_more": " Would you like to hear another one?",
        "joke_out": "I'm all out of fresh jokes! Give me some time to think of new ones.",
        "thanks": [
            "You're welcome! Is there anything else I can help with?", "My pleasure! What else would you like to know?",
            "Happy to help! Let me know if you need anything else.", "Anytime! That's what I'm here for."
        ],
        "capabilities": [
            "I can tell you the time, tell jokes, chat with you, and respond to basic questions. I'm always learning new things! What would you like me to do?",
            "I'm a voice assistant that can have conversations, tell you the time, share jokes, and remember context from our chat. How can I assist you?",
            "I can understand natural language, remember our conversation context, tell jokes, and respond to various commands. What would you like to try?"
        ],
        "about_you": [
            "I'm Shadow Bot, a voice assistant designed to help with various tasks and have conversations. I can understand natural language and remember our conversation context.",
            "I'm an AI assistant called Shadow Bot. I was created to have helpful conversations and assist with simple tasks like telling the time or sharing jokes.",
            "I'm Shadow Bot, a voice-controlled assistant. I use speech recognition to understand what you say and text-to-speech to respond. I'm here to help and chat!"
        ],
        "how_made": [
            "I was developed by  a group of student from Patuakhali Science and Technology University.",
            "I was developed by  a group of student from Patuakhali Science and Technology University.",
            "I was developed by  a group of student from Patuakhali Science and Technology University."
        ],
        "weather": [
            "I don't have access to real-time weather data, but I'd be happy to chat about other topics!",
            "Unfortunately, I can't check the weather for you. Is there something else I can help with?",
            "I don't have weather capabilities yet, but I'm learning new skills all the time!"
        ],
        "exit": [
            "Goodbye! It was nice chatting with you.", "See you later! Have a great day.",
            "Goodbye! I'll be here when you need me again.", "Shutting down. It was a pleasure talking with you!"
        ],
        "yes_generic": "Great! What would you like to talk about?",
        "no_generic": "Alright. Is there something else you'd like to discuss?",
        "why": [
            "That's an interesting question! I'm designed to respond this way to be helpful.",
            "I'm programmed to provide the most relevant information I can.",
            "Good question! My responses are based on my programming and conversation context."
        ],
        "what_else": [
            "I can tell you the time, tell jokes, chat about various topics, or just have a friendly conversation. What interests you?",
            "We could talk about how I was made, I could tell you a joke, or we could just chat. What would you prefer?",
            "I'm happy to continue our conversation! We could discuss my capabilities, I could tell you a joke, or we could chat about something else."
        ],
        "unknown":
           [ "I'm not sure I understand. Could you rephrase that?",
            "I'm still learning and didn't quite catch that. What would you like to talk about?",
            "Hmm, I'm not familiar with that. Would you like to know what I can do?",
            "I didn't understand that completely. Would you like to chat about something else?",
            "I'm not programmed to understand that yet, but I'm always learning! What else would you like to discuss?"
        ],
        "unknown_personalized": "I'm sorry, {name}, I didn't quite understand that. Could you try saying it differently?",
        "followup_name": "By the way, what's your name?",
        "followup_how_are_you": "How are you doing today?",
        "idle_prompt1": "I'm still here if you need anything.",
        "idle_prompt2": "Just let me know if you'd like to chat.",
        "no_command": "I didn't hear anything. Could you please repeat?",
        "wake_word_listening": "I'm listening",
        "wake_word_enabled_msg": "Wake word detection is enabled. Say {wake_word} to activate me.",
        "activated_msg": "Shadow Bot activated and ready.",
        "initial_greeting": "I'm here to chat and help you. Feel free to ask me questions or just have a conversation!",
        "interrupt_msg": "Interrupt detected. Shutting down.",
        "error_loop_msg": "I encountered an error. Let me restart my listening process.",
        "shutdown_msg": "Shadow Bot shutting down.",
        "goodbye_msg": "Shadow Bot has shut down. Goodbye!",
        "goodbye_personalized": "Shadow Bot has shut down. Goodbye, {name}!",
        "critical_error_msg": "A critical error occurred. Shadow Bot must shut down.",
        "gemini_error": "Sorry, I couldn't connect to my knowledge base right now.",
        "generic_error": "Sorry, an internal error occurred."
    },
    "bn": {
        "greeting": [
            "??????! ??? ?????? ??????? ???? ?????", "???! ????? ???? ?? ???? ?????",
            "???! ????? ??? ???? ???? ??????", "????????! ??? ????? ?????? ?????"
        ],
        "greeting_repeat": "????? ??????! ?????? ?? ??? ????????????? ?????? ??? ?????? ??????? ???? ?????",
        "greeting_followup": " ???? ?? ???? ?????",
        "how_are_you": [
            "??? ???? ???, ???????? ???? ???? ???????! ???? ???? ?????", "??? ???????? ??? ????! ???? ???? ?????",
            "?? ??????? ???? ???! ????? ??? ???? ???????", "??? ????? ???! ???????? ???? ???? ?????"
        ],
        "how_are_you_resp_glad": "???? ???? ?????! ??? ?? ?????? ?????? ??????? ???? ?????",
        "how_are_you_resp_sorry": "???? ?????? ????? ??? ?? ?????? ???????? ??????? ???? ?????",
        "time": "??? ???? {current_time}?",
        "time_repeat": "???? {current_time} ????? ??? ???? ???? ????? ??? ????!",
        "name": "???? ??? ?????? ??? ??? ????? ????? ????????????????",
        "name_repeat": "??? ???? ?????, ???? ??? ?????? ??? ??? ???? ??? ????? ??, ??? ??????!",
        "name_ask": "???? ??? ?????? ??? ??? ????? ????? ???????????????? ????? ??? ???",
        "user_name_confirm": "????? ???? ?????? ???? ???? ?????, {name}! ??? ?? ?????? ?????? ??????? ???? ?????",
        "user_name_fail": "??? ????? ????? ??? ????? ??????? ???? ?? ???? ??????",
        "joke": [
            "?????????? ???????? ??????? ??? ?? ???? ???? ???? ?????? ???? ???!", "??? ???????? ?? ???? ?????????!",
            "??????????? ??? ???????? ???????? ???? ?? ??? ???????? ???????? ???!", "???????? ?????? ??? ?? ???? ???? ???? ?????!",
            "?????? ??? ???? ??? ??? ???? ??? ????? ??????? ?????!", "?????? ?????? ?? ??????? ????? ??, ???? ??? ????????!",
            "???????? ??? ???? ????????? ???? ??? ??-???????? ???!", "???? ???? ??? ????? ????? ??? ???? ??? ??? ???? ????!",
            "?????? ??? ????? ???? ?????? ??? ???? ?? ??? ????? ????!", "??? ???? ???????? ???????? ?? ??? ???? ??? ?????? ?????? ?? ???? ???? ??????? ???!"
        ],
        "joke_ask_more": " ???? ?? ?????? ????? ????",
        "joke_out": "???? ???? ???? ???? ???? ???! ????? ???? ???? ????? ???? ???? ????",
        "thanks": [
            "?????? ???????! ??? ?? ???? ?????? ??????? ???? ?????", "???? ?????! ???? ?? ?? ????? ????",
            "??????? ???? ???? ????! ???? ???? ????? ????????", "??????! ??? ?????? ????? ????"
        ],
        "capabilities": [
            "??? ???? ???? ????, ???? ???? ????, ????? ???? ??? ???? ???? ??? ?????? ???????? ????? ???? ????? ??? ?????? ???? ????? ?????! ???? ?? ??? ??? ????",
            "??? ???? ????? ??????????????? ?? ??? ???? ????, ???? ???? ????, ???? ?????? ???? ???? ??? ?????? ??????? ??????? ??? ????? ????? ??? ?????? ?????? ??????? ???? ?????",
            "??? ????????? ???? ????? ????, ?????? ????????? ??????? ??? ????? ????, ???? ???? ???? ??? ??????? ???????? ????? ???? ????? ???? ?? ?????? ???? ????"
        ],
        "about_you": [
            "??? ?????? ??, ???? ????? ??????????????? ?? ??????? ???? ??????? ???? ???? ??? ??????? ???? ???? ?????? ??? ??????? ??? ????????? ???? ????? ???? ??? ?????? ????????? ??????? ??? ????? ?????",
            "??? ?????? ?? ???? ???? ??? ???????????????? ????? ?????? ??????? ???? ???? ??? ???? ??? ?? ???? ?????? ???? ??? ??? ????????? ??????? ???? ???? ???? ??? ???????",
            "??? ?????? ??, ???? ?????-??????????? ??????? ???? ?? ???? ?? ????? ???? ??? ????? ???????? ??? ???????????? ?????? ??????-??-????? ??????? ???? ??? ??????? ??? ????? ???? ???? ????? ???!"
        ],
        "how_made": [
            "????? ????? ??????? ??? ????? ???????? ??? ??????-??-????? ????????? ????? ???? ??? ??????? ???? ???????? ???? ????????? ?? ???? ?????????? ??? ??? ????????? ??? ?????? ??? ???????????? ???? ????",
            "????? ????? ??????????? ???? ????? ???? ??? ??????, ?????? ????? ???? ????? ???????? ??? ???????????? ?????? ??????-??-????? ??????? ???? ????? ????????? ??????? ???? ???? ?????? ??? ???????",
            "???? ??????? ????? ????? ??????? ??? ????????????? ??? ????????-?? ??? ????????? ????? ???? ??????? ????? ????????? ???? ????? ???? ??? ????????? ??????? ????? ????? ???? ?????? ??? ???????"
        ],
        "weather": [
            "???? ???? ??????-???? ????????? ???? ????????? ???, ??? ??? ???????? ?????? ??? ???? ???? ???? ??!",
            "????????????, ??? ????? ???? ???????? ??????? ???? ????? ??? ??? ?? ???? ?????? ??????? ???? ?????",
            "???? ???? ????????? ?????? ???, ??? ??? ?????? ???? ?????? ?????!"
        ],
        "exit": [
            "??????! ????? ???? ??? ??? ???? ??????", "??? ???? ???! ????? ????? ???? ??????",
            "??????! ????? ???? ???????? ??? ??? ????? ?????", "???? ?????? ????? ???? ??? ????? ??????? ???!"
        ],
        "yes_generic": "?????! ???? ?? ?????? ??? ???? ????",
        "no_generic": "?????? ???? ?? ???? ???? ?????? ???? ????",
        "why": [
            "??? ???? ???? ??????! ????? ?????? ?????? ???? ?????? ???????????? ?????? ?????? ??? ???????",
            "??? ???? ????? ?????????? ???? ?????? ???? ???? ????????? ??? ???????",
            "???? ??????! ???? ???????????????? ???? ??????????? ??? ????????? ????????? ??? ?????? ????"
        ],
        "what_else": [
            "??? ???? ???? ????, ???? ???? ????, ??????? ?????? ????? ???? ????, ???? ???? ???? ????????????? ??????? ???? ????? ????? ???? ??????",
            "???? ?????? ???? ???? ?????? ????? ???? ??? ??????, ??? ?????? ???? ??? ???? ????, ???? ???? ???? ????? ???? ????? ???? ????? ????? ??????",
            "??? ?????? ??????? ??????? ???? ???? ????! ???? ???? ?????? ????? ?????? ???? ????, ??? ?????? ???? ??? ???? ????, ???? ???? ???? ???? ????? ????? ???? ?????"
        ],
        "unknown": [
            "??? ??? ????? ????? ??? ???? ?? ???????? ???? ???????",
            "??? ???? ????? ??? ??? ??? ???? ??????? ???? ?? ?????? ??? ???? ????",
            "???, ??? ?? ???? ?????? ??? ???? ?? ????? ??? ??? ?? ???? ?????",
            "??? ??? ???????? ????? ??????? ???? ?? ???? ???? ????? ????? ???? ????",
            "????? ???? ??? ????? ???? ????????? ??? ?????, ??? ??? ?????? ?????! ???? ?? ?? ?????? ???? ????"
        ],
        "unknown_personalized": "??? ??????, {name}, ??? ??? ??? ????? ??????? ???? ?? ???????? ???? ?????? ??????",
        "followup_name": "??????, ????? ??? ???",
        "followup_how_are_you": "???? ?? ???? ?????",
        "idle_prompt1": "????? ??? ????? ???????? ??? ??? ??? ???? ????? ????",
        "idle_prompt2": "???? ????? ???? ????? ???? ????? ??????",
        "no_command": "??? ???? ????? ?????? ???? ?? ???? ??? ??????????? ??????",
        "wake_word_listening": "??? ?????",
        "wake_word_enabled_msg": "????? ??????? ????????? ??????? ??? ??????? ????? ??????? ???? {wake_word} ?????",
        "activated_msg": "?????? ?? ??????? ??? ?????????",
        "initial_greeting": "??? ????? ????? ???? ??? ?????? ??????? ???? ?????? ???????????? ????? ?????? ???????? ???? ?? ???? ???? ??????? ????!",
        "interrupt_msg": "???? ?????? ??? ??????? ???? ??? ??????",
        "error_loop_msg": "??? ???? ?????? ???????? ??????? ????? ???? ????? ?????????? ??????? ???? ???? ????",
        "shutdown_msg": "?????? ?? ???? ??????",
        "goodbye_msg": "?????? ?? ???? ???? ????? ??????!",
        "goodbye_personalized": "?????? ?? ???? ???? ????? ??????, {name}!",
        "critical_error_msg": "???? ?????? ?????? ?????? ?????? ?? ?????? ???? ???? ????",
        "gemini_error": "??????, ??? ?? ???????? ???? ????? ????????? ???? ????? ???? ????? ???",
        "generic_error": "??????, ???? ?????????? ?????? ??????"
    }
}

# Topics that can lead to follow-up questions (Bilingual) - Simplified for now
# We can expand this later if needed
conversation_topics = {
    "user_name": {"asked": False},
    "how_are_you": {"asked": False}
}

# --- Error Handling Helpers ---

def retry_operation(operation_func, *args, **kwargs):
    """
    Retry an operation multiple times with a delay between attempts.
    """
    for attempt in range(MAX_RETRY_ATTEMPTS):
        try:
            return operation_func(*args, **kwargs)
        except Exception as e:
            print(f"Operation failed (attempt {attempt+1}/{MAX_RETRY_ATTEMPTS}): {e}")
            if attempt < MAX_RETRY_ATTEMPTS - 1:
                print(f"Retrying in {RETRY_DELAY} seconds...")
                time.sleep(RETRY_DELAY)
            else:
                print("Maximum retry attempts reached. Operation failed.")
                return None

# --- Core Functions ---

def speak(text):
    """Converts text to speech using gTTS and plays it using pydub."""
    print(f"Shadow Bot: {text}")

    def _speak_operation():
        tts = gTTS(text=text, lang="en", slow=False)
        with tempfile.NamedTemporaryFile(delete=True, suffix=".mp3") as fp:
            temp_path = fp.name
            tts.save(temp_path)
            sound = AudioSegment.from_mp3(temp_path)
            play(sound)
        return True

    result = retry_operation(_speak_operation)
    if result is None:
        print("Failed to speak. Using fallback print method.")

def listen_for_audio(timeout=5, phrase_time_limit=10, adjust_noise=True):
    """
    Base function to listen for audio input.
    """
    r = sr.Recognizer()
    r.pause_threshold = PAUSE_THRESHOLD
    if not DYNAMIC_ENERGY_THRESHOLD:
        try:
            r.energy_threshold = ENERGY_THRESHOLD
        except NameError:
            print("Warning: DYNAMIC_ENERGY_THRESHOLD is False, but ENERGY_THRESHOLD is not defined. Using default.")

    with sr.Microphone() as source:
        if adjust_noise and DYNAMIC_ENERGY_THRESHOLD:
            print(f"Adjusting for ambient noise ({ADJUST_NOISE_DURATION} sec)...")
            r.adjust_for_ambient_noise(source, duration=ADJUST_NOISE_DURATION)
            print(f"Dynamic energy threshold set to: {r.energy_threshold:.2f}")
        elif not DYNAMIC_ENERGY_THRESHOLD:
            print(f"Using fixed energy threshold: {r.energy_threshold}")

        try:
            print(f"Listening... (Timeout: {timeout}s, Pause Threshold: {r.pause_threshold}s, Phrase Limit: {phrase_time_limit}s)")
            audio = r.listen(source, timeout=timeout, phrase_time_limit=phrase_time_limit)
            return audio
        except sr.WaitTimeoutError:
            print("No audio detected within timeout period.")
            return None
        except Exception as e:
            print(f"Error capturing audio: {e}")
            return None

def recognize_speech(audio):
    """
    Attempt to recognize speech in English.
    """
    if audio is None:
        return None

    r = sr.Recognizer()
    try:
        print("Attempting recognition in English...")
        text = r.recognize_google(audio, language="en-US")
        print(f"Recognized: {text}")
        return text.lower()
    except sr.UnknownValueError:
        print("Could not understand audio.")
        return None
    except sr.RequestError as e:
        print(f"Could not request results from Google; {e}")
        return None
    except Exception as e:
        print(f"Error during speech recognition: {e}")
        return None

def listen_for_command():
    """
    Listens for a command after wake word (if enabled).
    """
    if WAKE_WORD_ENABLED:
        if not listen_for_wake_word():
            return None
        speak(get_response_string("wake_word_listening"))

    print("Listening for command...")
    audio = listen_for_audio(timeout=WAKE_WORD_TIMEOUT if WAKE_WORD_ENABLED else 5)
    return recognize_speech(audio)

def match_command(command_text):
    """
    Match the command text to the closest command template.
    """
    if command_text is None:
        return None, 0

    best_match = None
    best_confidence = 0

    for command_type, templates in command_templates["en"].items():
        match, confidence = process.extractOne(command_text, templates)
        if confidence > best_confidence:
            best_match = command_type
            best_confidence = confidence

    if best_confidence >= COMMAND_SIMILARITY_THRESHOLD * 100:
        return best_match, best_confidence
    else:
        return None, 0

# --- Conversation State ---
conversation_state = {
    "current_topic": None,
    "expecting_response": False,
    "last_question": None,
    "user_name": None,
    "session_start_time": time.time()
}

def extract_user_name(command):
    """
    Extract a user's name from commands.
    """
    patterns = [
        r"(?:my name is|i am|i'm|call me) ([a-z]+)",
        r"([a-z]+) is my name"
    ]

    for pattern in patterns:
        match = re.search(pattern, command, re.IGNORECASE)
        if match:
            return match.group(1).capitalize()

    return None

def get_response_string(key, **kwargs):
    """
    Retrieve a response string for the given key, performing formatting.
    """
    response_options = responses["en"].get(key)
    if response_options is None:
        print(f"Error: Response key '{key}' not found.")
        return responses["en"].get("generic_error")

    if isinstance(response_options, list):
        chosen_response = random.choice(response_options)
    else:
        chosen_response = response_options

    try:
        return chosen_response.format(**kwargs)
    except KeyError as e:
        print(f"Error formatting response key '{key}': Missing key {e}")
        return chosen_response

def get_contextual_response(command_type, command_text):
    """
    Generate a response based on command and context.
    """
    recent_command_types = [item["command_type"] for item in context_memory]
    repetition = recent_command_types.count(command_type) if command_type else 0
    should_ask_followup = False
    response_text = ""

    # --- Handle response to previous question ---
    if conversation_state["expecting_response"] and conversation_state["last_question"]:
        last_q = conversation_state["last_question"]
        conversation_state["expecting_response"] = False

        if last_q == "name" and command_type in ["user_name", "yes", "no"]:
            name = extract_user_name(command_text)
            if name:
                conversation_state["user_name"] = name
                response_text = get_response_string("user_name_confirm", name=name)
            else:
                response_text = get_response_string("user_name_fail")
            return response_text, False

        elif last_q == "how_are_you" and command_type:
            if command_type in ["greeting", "how_are_you", "yes"]:
                response_text = get_response_string("how_are_you_resp_glad")
            elif command_type == "no":
                response_text = get_response_string("how_are_you_resp_sorry")
                should_ask_followup = True
            else:
                response_text = get_response_string("unknown")
            return response_text, should_ask_followup

        elif last_q == "another_joke":
            if command_type == "yes":
                command_type = "joke"
            else:
                response_text = get_response_string("no_generic")
                return response_text, False

    # --- Handle specific command types ---
    if command_type == "greeting":
        if conversation_state["user_name"]:
            first_greeting = random.choice(responses["en"]["greeting"])
            greeting_part1 = first_greeting.split('!')[0] if '!' in first_greeting else first_greeting
            greeting_part2 = first_greeting.split('!')[1] if '!' in first_greeting and len(first_greeting.split('!')) > 1 else ""
            personalized_greeting = f"{greeting_part1}, {conversation_state['user_name']}!"
            response_text = personalized_greeting + greeting_part2
        else:
            response_text = random.choice(responses["en"]["greeting"])

        if repetition > 1:
            response_text = get_response_string("greeting_repeat")
        elif random.random() < 0.3:
            conversation_state["expecting_response"] = True
            conversation_state["last_question"] = "how_are_you"
            response_text += get_response_string("greeting_followup")

    elif command_type == "how_are_you":
        response_text = get_response_string("how_are_you")
        conversation_state["expecting_response"] = True
        conversation_state["last_question"] = "how_are_you"

    elif command_type == "time":
        current_time_str = time.strftime("%I:%M %p")
        if repetition > 1:
            response_text = get_response_string("time_repeat", current_time=current_time_str)
        else:
            response_text = get_response_string("time", current_time=current_time_str)

    elif command_type == "name":
        if repetition > 1:
            response_text = get_response_string("name_repeat")
        elif not conversation_state["user_name"] and random.random() < 0.5:
            conversation_state["expecting_response"] = True
            conversation_state["last_question"] = "name"
            response_text = get_response_string("name_ask")
        else:
            response_text = get_response_string("name")

    elif command_type == "user_name":
        name = extract_user_name(command_text)
        if name:
            conversation_state["user_name"] = name
            response_text = get_response_string("user_name_confirm", name=name)
        else:
            response_text = get_response_string("user_name_fail")

    elif command_type == "joke":
        used_jokes = [item["response"] for item in context_memory if item["command_type"] == "joke"]
        available_jokes = [j for j in responses["en"]["joke"] if j not in used_jokes]

        if available_jokes:
            joke = random.choice(available_jokes)
            response_text = joke
            if random.random() < 0.3:
                conversation_state["expecting_response"] = True
                conversation_state["last_question"] = "another_joke"
                response_text += get_response_string("joke_ask_more")
        else:
            response_text = get_response_string("joke_out")

    elif command_type == "thanks":
        response_text = get_response_string("thanks")

    elif command_type == "capabilities":
        response_text = get_response_string("capabilities")

    elif command_type == "about_you":
        response_text = get_response_string("about_you")

    elif command_type == "how_made":
        response_text = get_response_string("how_made")

    elif command_type == "weather":
        response_text = get_response_string("weather")

    elif command_type == "exit":
        name = conversation_state.get("user_name")
        if name:
            response_text = get_response_string("goodbye_personalized", name=name)
        else:
            response_text = random.choice(responses["en"]["exit"])

    elif command_type == "yes" and not conversation_state["last_question"]:
        response_text = get_response_string("yes_generic")
    elif command_type == "no" and not conversation_state["last_question"]:
        response_text = get_response_string("no_generic")

    elif command_type == "why":
        response_text = get_response_string("why")

    elif command_type == "what_else":
        response_text = get_response_string("what_else")

    # --- Unknown command: Fallback to Gemini ---
    else:
        print(f"Command type '{command_type}' not recognized or no match. Querying Gemini...")
        gemini_response = get_gemini_response(command_text)
        response_text = gemini_response
        should_ask_followup = False

    return response_text, should_ask_followup

def generate_follow_up_question():
    """
    Generate a follow-up question based on context.
    """
    if not conversation_state["user_name"] and random.random() < 0.2:
        conversation_state["expecting_response"] = True
        conversation_state["last_question"] = "name"
        return get_response_string("followup_name")

    session_duration = time.time() - conversation_state["session_start_time"]
    if session_duration > 60 and random.random() < 0.3:
        conversation_state["expecting_response"] = True
        conversation_state["last_question"] = "how_are_you"
        return get_response_string("followup_how_are_you")

    return None

def process_command(command):
    """
    Processes the command text.
    """
    if command is None:
        if WAKE_WORD_ENABLED and not wake_word_activated:
            return True
        else:
            speak(get_response_string("no_command"))
            return True

    print(f"Processing command '{command}'")

    # Check if command starts with "how"
    if command.lower().startswith("how"):
        response = get_gemini_response(command)
        speak(response)
        return True

    command_type, confidence = match_command(command)
    response, should_ask_followup = get_contextual_response(command_type, command)

    context_memory.append({
        "timestamp": time.time(),
        "command": command,
        "command_type": command_type,
        "confidence": confidence,
        "response": response
    })

    speak(response)

    if should_ask_followup:
        follow_up = generate_follow_up_question()
        if follow_up:
            time.sleep(0.5)
            speak(follow_up)

    if command_type == "exit":
        return False

    return True

# --- Main Execution ---

if __name__ == "__main__":
    try:
        conversation_state["session_start_time"] = time.time()

        speak(get_response_string("activated_msg"))

        if WAKE_WORD_ENABLED:
            speak(get_response_string("wake_word_enabled_msg", wake_word=WAKE_WORDS[0]))
            if not listen_for_wake_word():
                print("Wake word not detected. Exiting...")
                exit(0)
            speak(get_response_string("wake_word_listening"))

        time.sleep(0.5)
        speak(get_response_string("initial_greeting"))

        running = True
        idle_time = 0
        last_activity = time.time()

        while running:
            try:
                current_time = time.time()
                if current_time - last_activity > 30 and idle_time == 0:
                    speak(get_response_string("idle_prompt1"))
                    idle_time += 1
                elif current_time - last_activity > 60 and idle_time == 1:
                    speak(get_response_string("idle_prompt2"))
                    idle_time += 1

                command = listen_for_command()

                if command is not None:
                    last_activity = time.time()
                    idle_time = 0
                    running = process_command(command)
                else:
                    running = True

                time.sleep(0.1)

            except KeyboardInterrupt:
                speak(get_response_string("interrupt_msg"))
                running = False
            except Exception as e:
                print(f"Error in main loop: {e}")
                speak(get_response_string("error_loop_msg"))
                time.sleep(1)

        print(get_response_string("shutdown_msg"))

        name = conversation_state.get("user_name")
        if name:
            speak(get_response_string("goodbye_personalized", name=name))
        else:
            speak(get_response_string("goodbye_msg"))

    except Exception as e:
        print(f"Critical error: {e}")
        speak(get_response_string("critical_error_msg"))


